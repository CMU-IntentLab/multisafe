<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="Safe control techniques, such as Hamilton-Jacobi reachability, provide principled methods for synthesizing safety-preserving robot policies but typically assume hand-designed state spaces and full observability. Recent work has relaxed these assumptions via latent-space safe control, where state representations and dynamics are learned jointly through world models that reconstruct future high-dimensional observations (e.g., RGB images) from current observations and actions. This enables safety constraints that are difficult to specify analytically (e.g., spilling) to be framed as classification problems in latent space, allowing controllers to operate directly from raw observations. However, these methods assume that safety-critical features are observable in the learned latent state. We ask: when are latent state spaces sufficient for safe control? To study this, we examine temperature-based failures, comparable to overheating in cooking or manufacturing tasks, and find that RGB-only observations can produce myopic safety behaviors, e.g., avoiding seeing failure states rather than preventing failure itself. To predict such behaviors, we introduce a mutual information-based measure that identifies when observations fail to capture safety-relevant features. Finally, we propose a multimodal-supervised training strategy that shapes the latent state with additional sensory inputs during training, but requires no extra modalities at deployment, and validate our approach in simulation and on hardware with a Franka Research 3 manipulator preventing a pot of wax from overheating.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="latent-space safe control, partially observable safety constraints, mutual information, multimodal machine learning, robotics">
  <!-- TODO: List all authors -->
  <meta name="author" content="Matthew Kim, Kensuke Nakamura, Andrea Bajcsy">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Intent Robotics Lab">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="Safe control techniques, such as Hamilton-Jacobi reachability, provide principled methods for synthesizing safety-preserving robot policies but typically assume hand-designed state spaces and full observability. Recent work has relaxed these assumptions via latent-space safe control, where state representations and dynamics are learned jointly through world models that reconstruct future high-dimensional observations (e.g., RGB images) from current observations and actions. This enables safety constraints that are difficult to specify analytically (e.g., spilling) to be framed as classification problems in latent space, allowing controllers to operate directly from raw observations. However, these methods assume that safety-critical features are observable in the learned latent state. We ask: when are latent state spaces sufficient for safe control? To study this, we examine temperature-based failures, comparable to overheating in cooking or manufacturing tasks, and find that RGB-only observations can produce myopic safety behaviors, e.g., avoiding seeing failure states rather than preventing failure itself. To predict such behaviors, we introduce a mutual information-based measure that identifies when observations fail to capture safety-relevant features. Finally, we propose a multimodal-supervised training strategy that shapes the latent state with additional sensory inputs during training, but requires no extra modalities at deployment, and validate our approach in simulation and on hardware with a Franka Research 3 manipulator preventing a pot of wax from overheating.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://cmu-intentlab.github.io/multisafe/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="static/images/unicycletoast.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/intent_logo_icon_transparent-highQuality (1).png">
  <link rel="apple-touch-icon" href="static/images/intent_logo_icon_transparent-highQuality (1).png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-2 publication-title">What You Don't Know <i>Can</i> Hurt You: <br> How Well do Latent Safety
              Filters Understand Partially Observable Safety Constraints?</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/mattkiim/" target="_blank">Matthew Kim</a><sup>*1</sup>,</span>
                <span class="author-block">
                  <a href="https://kensukenk.github.io/" target="_blank">Kensuke Nakamura</a><sup>*2</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.cs.cmu.edu/~abajcsy/" target="_blank">Andrea Bajcsy
                    </a><sup>2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!--<span class="author-block">Institution Name<br>Conference name and year</span>-->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small>  <small><sup>1</sup>UC San Diego</small>  <small><sup>2</sup>Carnegie Mellon University</small></span>
                  </div>

          

                  <span class="link-block">
                    <a href="https://github.com/CMU-IntentLab/multisafe" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code [coming soon]</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv [coming soon]</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <!-- TODO: Replace with your paper abstract -->
            <p>
              Safe control techniques, such as Hamilton-Jacobi reachability, 
              provide principled methods for synthesizing safety-preserving 
              robot policies but typically assume hand-designed state spaces 
              and full observability. Recent work has relaxed these assumptions
              via <i>latent-space</i> safe control, where state representations
              and dynamics are learned jointly through world models that 
              reconstruct future high-dimensional observations (e.g., RGB images)
              from current observations and actions. This enables safety 
              constraints that are difficult to specify analytically 
              (e.g., spilling) to be framed as classification problems in 
              latent space, allowing controllers to operate directly from 
              raw observations. However, these methods assume that 
              safety-critical features are observable in the learned latent
              state. We ask: <i>when are latent state spaces sufficient
              for safe control?</i> To study this, we examine temperature-based
              failures, comparable to overheating in cooking or manufacturing
              tasks, and find that RGB-only observations can produce myopic
              safety behaviors, e.g., avoiding <i>seeing failure</i>
              states rather than preventing failure itself. To predict 
              such behaviors, we introduce a mutual information-based 
              measure that identifies when observations fail to capture 
              safety-relevant features. Finally, we propose a 
              multimodal-supervised training strategy that shapes the 
              latent state with additional sensory inputs during training,
              but requires no extra modalities at deployment, and validate
              our approach in simulation and on hardware with a Franka 
              Research 3 manipulator preventing a pot of wax from 
              overheating.          
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

<!-- Motivation / Problem Setup -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">When Latent Safety Filters Miss What Matters</h2>
        <div class="content has-text-justified">
          <p>
            Latent-space safety filters enable safe control directly from raw sensory data by learning compact state representations and safety boundaries jointly. However, these methods typically assume that all safety-critical information is observable in the sensory input. In many real-world tasks, this assumption breaks down because safety often depends on hidden or indirectly observable variables such as force, friction, or temperature. When these unobserved factors drive unsafe outcomes, controllers trained only on visible cues can appear safe while actually failing to prevent danger.
          </p>
          <p>
            To study this challenge concretely, we focus on temperature as a representative partially observable safety variable. By examining heating tasks where RGB cameras cannot fully perceive temperature rise, we show how latent safety filters behave when the true risk is invisible, and how multimodal supervision can recover reliable safety behavior.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper Environments -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 center-title">Environments</h2>

        <div class="content has-text-justified">
          <figure class="image is-centered">
            <!-- Replace with your image path -->
            <img src="static/images/mm_envs.png" alt="Environment visualization">
          </figure>
          <p>
            Experiment Testbeds. In simulation (left) and hardware (right) we control data from two sensors: RGB and infrared (IR) camera. In our controlled experiments, the ground-truth safety-relevant state variable is heat, which is more observable from the IR data than the RGB.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper environments -->

<!-- [start] mutual information -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Mutual Information as a Measure of Observability</h2>
        <div class="content has-text-justified">
          <figure class="image is-centered">
            <img src="static/images/MI_metric.png" alt="MI reveals greater separation than accuracy-based metrics for quantifying the observability of safety constraints from high-D obs" width="1100">
          </figure>

          <p>
          Our mutual information (MI) metric quantifies how much uncertainty about safety outcomes is reduced by observing a particular input modality (e.g., RGB or infrared). We compute a Barber-Agakov lower bound on MI between observations and binary safety labels to measure how well each modality captures safety-relevant features. Higher MI indicates that the modality more reliably encodes features necessary for safety prediction. We find that IR observations exhibit much higher normalized MI than RGB alone, meaning RGB-only models often lack sufficient safety information, which explains their myopic, “avoid seeing failure” behaviors.
          </p>

        </div>
      </div>
    </div>
  </div>
</section>
<!-- [end] mutual information -->


<!-- latent state and imagination test -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Examining Latent Representation Quality</h2>
        <div class="content has-text-justified">
          <figure class="image is-centered">
            <img src="static/images/hw_qual_v3.png" alt="RGB-only training is unable to understand safety outcomes of actions" width="1100">
          </figure>
          <p>
            We evaluate the quality of the learned latent representations by examining how well they encode safety-relevant state information. Models trained only on RGB observations often produce latent states that fail to represent temperature, leading to visually correct but unsafe predictions. In contrast, our multimodal-supervised approach—trained with both RGB and IR data but deployed with RGB alone—learns latent states that embed the underlying thermal dynamics, enabling proactive interventions that maintain safety.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- simulation -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Simulation Experiments</h2>

        <div class="columns has-text-justified">
          <div class="column">
            <h3 class="title is-4">RGB-Only Safety Filter</h3>
            <video width="100%" controls>
              <source src="static/videos/rgb_demo_dubins.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <p>
              RGB-only safety filter: The agent avoids visually unsafe states but fails to prevent actual overheating events due to missing thermal cues.
            </p>
          </div>

          <div class="column">
            <h3 class="title is-4">Multimodal Safety Filter</h3>
            <video width="100%" controls>
              <source src="static/videos/mm_demo_dubins.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <p>
              Multimodal safety filter: The agent predicts temperature rise early and moves out of the hot region before failure occurs.
            </p>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>

<!-- hardware -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Hardware Experiments</h2>

        <div class="columns has-text-justified">
          <div class="column">
            <h3 class="title is-4">RGB-Only Safety Filter</h3>
            <video width="100%" controls>
              <source src="static/videos/rgb_demo.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <p>
              RGB-only safety filter on the Franka Research 3 manipulator fails to provide safe actions, allowing the pot of wax to overheat.
            </p>
          </div>

          <div class="column">
            <h3 class="title is-4">Multimodal Safety Filter</h3>
            <video width="100%" controls>
              <source src="static/videos/mm_demo.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <p>
              Multimodal safety filter anticipates overheating and lifts the pot of wax early, maintaining safety using only RGB input during execution.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- hardware MM-RGB -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Hardware Experiments</h2>

        <div class="content has-text-justified">
          <video width="100%" controls>
            <source src="static/videos/masked_demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p>
            The multimodal-supervised safety filter also anticipates overheating and lifts the pan before the wax fails. Trained with RGB + IR data but deployed using only RGB, the controller maintains safety even under partial observability.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?},
  author={Matthew Kim and Kensuke Nakamura and Andrea Bajcsy},
  journal={Conference/Journal Name},
  year={2025},
  url={https://cmu-intentlab.github.io/multisafe/}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
